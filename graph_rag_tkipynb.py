# -*- coding: utf-8 -*-
"""Graph_rag_tkipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13NSud33ogRUopmDJugLBk_7YVfV6pKES
"""

!pip install --quiet datasets pandas networkx sentence-transformers faiss-cpu transformers langdetect deep-translator

import os
import time
from datasets import load_dataset
import pandas as pd
import networkx as nx
from sentence_transformers import SentenceTransformer, util
import faiss
from langdetect import detect
from deep_translator import GoogleTranslator
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

def detect_lang(text):
    try:
        return detect(text)
    except:
        return "en"

print("Loading dataset from HuggingFace...")
ds = load_dataset("Selvakumarduraipandian/Thirukural", split="train")
df = ds.to_pandas()

print(df.columns)
print("Rows:", len(df))

df['Kural'] = df['Kural'].astype(str).str.replace('<br />',' ').str.strip()

df['kural_id'] = df['Adhigaram_ID'].astype(str) + "." + df['ID'].astype(str)
df.head(3)

print("Building knowledge graph...")
G = nx.Graph()

for _, row in df.iterrows():
    node_id = f"Kural {row['kural_id']}"

    G.add_node(node_id, type="kural", text=row['Kural'], chapter=row['Adhigaram'], section=row['Section'])

    chapter_node = f"Chapter: {row['Adhigaram']}"
    section_node = f"Section: {row['Section']}"
    G.add_node(chapter_node, type="chapter")
    G.add_node(section_node, type="section")

    G.add_edge(node_id, chapter_node)
    G.add_edge(chapter_node, section_node)

print("Graph built: nodes", G.number_of_nodes(), "edges", G.number_of_edges())

print("Creating embeddings (paraphrase-multilingual-MiniLM-L12-v2)...")
embed_model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
kural_texts = df["Kural"].tolist()
kural_ids = df["kural_id"].tolist()
embeddings = embed_model.encode(kural_texts, show_progress_bar=True, convert_to_numpy=True)


d = embeddings.shape[1]
index = faiss.IndexFlatIP(d)

import numpy as np
emb_norm = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
index.add(emb_norm)
print("FAISS index ready, items:", index.ntotal)

print("Adding similarity edges (top-3 neighbors per kural)...")
k = 3
hits = util.semantic_search(embeddings, embeddings, top_k=k)
for i, lst in enumerate(hits):
    src_node = f"Kural {kural_ids[i]}"
    for hit in lst[1:]:
        j = hit['corpus_id']
        sim_node = f"Kural {kural_ids[j]}"

        G.add_edge(src_node, sim_node, relation="SIMILAR_TO", score=float(hit['score']))
print("Similarity edges added.")

print("Loading summarization/generation model (flan-t5-small)...")
tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-small")
gen_model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-small")

summarizer = pipeline("text2text-generation", model=gen_model, tokenizer=tokenizer, device=-1)

def ensure_tamil_query(query):
    lang = detect_lang(query)
    if lang == 'ta':
        return query, False
    else:

        try:
            tamil_q = GoogleTranslator(source='auto', target='ta').translate(query)
            return tamil_q, True
        except Exception as e:
            print("Translation failed, using original query:", e)
            return query, False

def hybrid_query(query, top_k=3, hop=1, summarize=True):
    """
    Returns structured Tamil output:
      - 'query_tamil' : the Tamil query used
      - 'retrieved_kurals' : list of (kural_id, text)
      - 'expanded_kurals' : list after graph expansion
      - 'summary' : optional short Tamil summary generated by model
    """

    query_ta, translated = ensure_tamil_query(query)

    q_emb = embed_model.encode([query_ta], convert_to_numpy=True)
    q_emb = q_emb / np.linalg.norm(q_emb, axis=1, keepdims=True)
    D, I = index.search(q_emb, top_k)
    top_idxs = I[0].tolist()

    top_nodes = [f"Kural {kural_ids[i]}" for i in top_idxs]
    retrieved = [(kural_ids[i], kural_texts[i]) for i in top_idxs]


    related_nodes = set()
    for node in top_nodes:
        if node in G:

            related_nodes.add(node)

            neighbors = nx.single_source_shortest_path_length(G, node, cutoff=hop).keys()
            related_nodes.update(neighbors)

    expanded = []
    for n in related_nodes:
        if G.nodes[n].get('type') == 'kural' or n.startswith('Kural '):

            k_id = n.split("Kural ")[-1] if n.startswith("Kural ") else None
            if k_id:

                try:
                    idx = kural_ids.index(k_id)
                    expanded.append((k_id, kural_texts[idx], G.nodes[n].get('chapter'), G.nodes[n].get('section')))
                except ValueError:
                    pass


    result = {
        "original_query": query,
        "query_tamil": query_ta,
        "translated_from_english": translated,
        "retrieved": retrieved,
        "expanded": expanded
    }


    if summarize and len(expanded) > 0:

        context_lines = []
        for k_id, text, chapter, section in expanded[:10]:
            context_lines.append(f"[குறள் {k_id}] {text} ({chapter} - {section})")
        prompt = "கீழ் கொடுக்கப்பட்ட குறள்களின் பொருளைப் பொறுத்து சுருக்கமாக, தெளிவாக தமிழில் பதில் சொல்லவும்:\n\n"
        prompt += "\n".join(context_lines) + "\n\nபொருள்:"

        gen = summarizer(prompt, max_new_tokens=128, do_sample=False)
        summary = gen[0]['generated_text']
        result['summary'] = summary
    else:
        result['summary'] = None

    return result

print("Example: Tamil query")
r1 = hybrid_query("திருக்குறள் நட்பு பற்றி என்ன கூறுகிறது", top_k=3, hop=1, summarize=True)
print("Query used (Tamil):", r1['query_tamil'])
print("Summary (Tamil):\n", r1['summary'])
print("\nExpanded kurals (sample):")
for k in r1['expanded'][:6]:
    print(k[0], ":", k[1])

print("\n\nExample: English query (auto-translate -> Tamil)")
r2 = hybrid_query("What does Thirukkural say about education", top_k=3, hop=1, summarize=True)
print("Query used (Tamil):", r2['query_tamil'])
print("Summary (Tamil):\n", r2['summary'])
print("\nExpanded kurals (sample):")
for k in r2['expanded'][:6]:
    print(k[0], ":", k[1])